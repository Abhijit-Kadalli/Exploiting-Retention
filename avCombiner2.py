import torch 
import torchvision.io as io
import json
import random
from moviepy.editor import VideoFileClip, ImageClip, concatenate_videoclips, CompositeVideoClip, AudioFileClip

def extract_video_duration(input_path, output_path, json_path):
    with open(json_path, 'r') as json_file:
        data = json.load(json_file)
    
    durationOfClips = 0
    for image_data in data:
        durationOfClips += image_data['duration']
    
    # Load the video
    video, audio, info = io.read_video(input_path)

    max_start_time = info["video_duration"] - durationOfClips

    start_time = random.randint(0, int(max_start_time))

    video_segment, _, _ = io.read_video(input_path, start_pts=start_time, end_pts=start_time + durationOfClips)

    # Save the extracted video
    io.write_video(output_path, video, info["video_fps"], video_codec="libx264", options=["-pix_fmt", "yuv420p"])

    print(f"Extracted video saved to {output_path} successfully!")
    return output_path

def add_images_with_padding(video, audio_path, json_path, output_path, padding):
    # Load the video
    video_clip = VideoFileClip(video)

    # Load the JSON file
    with open(json_path, 'r') as json_file:
        data = json.load(json_file)

    # Initialize a list to store the clips
    clips = []

    # Iterate over the image paths and durations
    for image_data in data:
        image_path = image_data['path']
        duration = image_data['duration']

        # Create an image clip from the image path
        image = ImageClip(image_path)

        # Set the duration of the image clip
        image = image.set_duration(duration)

        # Add padding to the image clip
        padded_image = image.resize(height=video_clip.h - 2 * padding).margin(
            top=padding, bottom=padding, left=padding, right=padding)

        # Concatenate the padded image clip
        clip = concatenate_videoclips([padded_image])

        # Add the clip to the list
        clips.append(clip)

    # Concatenate all the clips
    final_clip = concatenate_videoclips(clips)

    # Set the duration of the final clip
    final_clip = final_clip.set_duration(video_clip.duration)

    # Overlay the final clip on the original video
    final_video = CompositeVideoClip([video_clip.set_opacity(0.7), final_clip.set_opacity(0.7)])
    audio = AudioFileClip(audio_path)
    final_video = final_video.set_audio(audio)

    # Write the output video to file
    final_video.write_videofile(output_path, codec='libx264', audio_codec='aac', audio=True, threads=8)

video_path = "videos\Subway Surfers (2018) - Gameplay Compilation HD.mp4"
json_path = "comment_screenshots\Wedding_photographers_of_Reddit,_what_was_your_they're_not_gonna_last_long_moment\clip_info.json"
audio_path = "comment_screenshots\Wedding_photographers_of_Reddit,_what_was_your_they're_not_gonna_last_long_moment\all_comments.mp3"
output_path = "comment_screenshots\Wedding_photographers_of_Reddit,_what_was_your_they're_not_gonna_last_long_moment\snippet.mp4"
oput_path = "comment_screenshots\Wedding_photographers_of_Reddit,_what_was_your_they're_not_gonna_last_long_moment\final.mp4"
padding = 50
add_images_with_padding(extract_video_duration(video_path,output_path,json_path), audio_path,json_path, oput_path, padding)